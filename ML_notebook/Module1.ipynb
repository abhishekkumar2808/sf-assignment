{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Basics\n",
    "In this module, you'll be acquiring and handling datasets. You will be using the Cinema Data, Salary Data and Reviews Data for the tasks in this module. <br> <br>\n",
    "**Pipeline:**\n",
    "* Acquiring the data\n",
    "* Handling files and formats\n",
    "* Data Analysis\n",
    "* Prediction\n",
    "* Analysing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Data Acquisition\n",
    "* Retrieve the CinemaData dataset from Firebase, convert it to a CSV and save it in the 'Data' folder as 'CinemaData.csv'. You may use shell scripts, other packages and any other resources you require to do this. The database can be accessed with a HTTP request, ask a TA for the link. <br> \n",
    "* Using `wget`, download the 'SalaryData.txt' and save it in the 'Data' folder. Convert it to a CSV named 'SalaryData.csv' and save it in the same folder. It is avaliable at this link: <br>\n",
    "http://rebrand.ly/ml_salarydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "--2020-07-27 03:39:00--  https://sf-mlbasics.firebaseio.com/CinemaData.json\nResolving sf-mlbasics.firebaseio.com (sf-mlbasics.firebaseio.com)... 2600:1901:0:94b6::, 35.201.97.85\nConnecting to sf-mlbasics.firebaseio.com (sf-mlbasics.firebaseio.com)|2600:1901:0:94b6::|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 849446 (830K) [application/json]\nSaving to: 'CinemaData.json'\n\n     0K .......... .......... .......... .......... ..........  6%  194K 4s\n    50K .......... .......... .......... .......... .......... 12%  213K 4s\n   100K .......... .......... .......... .......... .......... 18% 2.53M 2s\n   150K .......... .......... .......... .......... .......... 24% 2.66M 2s\n   200K .......... .......... .......... .......... .......... 30%  230K 2s\n   250K .......... .......... .......... .......... .......... 36% 9.25M 1s\n   300K .......... .......... .......... .......... .......... 42% 6.39M 1s\n   350K .......... .......... .......... .......... .......... 48% 5.33M 1s\n   400K .......... .......... .......... .......... .......... 54%  235K 1s\n   450K .......... .......... .......... .......... .......... 60% 3.61M 1s\n   500K .......... .......... .......... .......... .......... 66% 5.97M 1s\n   550K .......... .......... .......... .......... .......... 72% 8.64M 0s\n   600K .......... .......... .......... .......... .......... 78% 4.06M 0s\n   650K .......... .......... .......... .......... .......... 84% 2.78M 0s\n   700K .......... .......... .......... .......... .......... 90% 7.24M 0s\n   750K .......... .......... .......... .......... .......... 96% 6.66M 0s\n   800K .......... .......... .........                       100% 7.56M=1.1s\n\n2020-07-27 03:39:03 (785 KB/s) - 'CinemaData.json' saved [849446/849446]\n\n      Capacity  DaysShowedInWeek  Index    LastDate  Lifetime       Movie  \\\n0         3100                 5      0  2015-12-17         2  0001000001   \n1         3390                 7      1  2015-12-17         2  0001000001   \n2          860                 2      2  2015-12-17         2  0001000001   \n3          110                 1      3  2016-01-06         5  0001000002   \n4          720                 6      4  2016-01-06         5  0001000002   \n...        ...               ...    ...         ...       ...         ...   \n3505       120                 1   3505  2017-11-15         0  HO00002188   \n3506      2410                 2   3506  2017-11-18         0  HO00002193   \n3507       330                 2   3507  2017-11-18         0  HO00002196   \n3508       360                 2   3508  2017-11-18         0  HO00002197   \n3509       220                 2   3509  2017-11-18         0  HO00002198   \n\n      OccAtWeek    OccPer  OtherReleasesInWeek ReleaseDate  ShowsInWeek  \\\n0          2494  0.804516                    8  2015-12-04           10   \n1          1932  0.569912                    4  2015-12-04           14   \n2           222  0.258140                    4  2015-12-04            4   \n3            59  0.536364                    8  2015-12-04            1   \n4           630  0.875000                    7  2015-12-04            6   \n...         ...       ...                  ...         ...          ...   \n3505        112  0.933333                    7  2017-11-15            1   \n3506       2318  0.961826                    7  2017-11-17            9   \n3507        255  0.772727                    7  2017-11-17            3   \n3508        304  0.844444                    7  2017-11-17            3   \n3509        162  0.736364                    7  2017-11-17            2   \n\n      WeeksSinceRelease  \n0                     0  \n1                     1  \n2                     2  \n3                     0  \n4                     3  \n...                 ...  \n3505                  0  \n3506                  0  \n3507                  0  \n3508                  0  \n3509                  0  \n\n[3510 rows x 12 columns]\n   YearsExperience  Salary\n0              1.1   39343\n1              1.3   46205\n2              1.5   37731\n3                2   43525\n4              2.2   39891\n5              2.9   56642\n6                3   60150\n7              3.2   54445\n8              3.2   64445\n9              3.7   57189\n10             3.9   63218\n11               4   55794\n12               4   56957\n13             4.1   57081\n14             4.5   61111\n15             4.9   67938\n16             5.1   66029\n17             5.3   83088\n18             5.9   81363\n19               6   93940\n20             6.8   91738\n21             7.1   98273\n22             7.9  101302\n23             8.2  113812\n24             8.7  109431\n25               9  105582\n26             9.5  116969\n27             9.6  112635\n28            10.3  122391\n29            10.5  121872\n--2020-07-27 03:39:03--  http://rebrand.ly/ml_salarydata\nResolving rebrand.ly (rebrand.ly)... 3.213.235.89, 3.214.100.252\nConnecting to rebrand.ly (rebrand.ly)|3.213.235.89|:80... connected.\nHTTP request sent, awaiting response... 301 Moved Permanently\nLocation: https://gist.githubusercontent.com/solarillion/4d13184683407dfb0b36c7130fce1567/raw/329a94a79de4ba49e916c632a625e1d754506d3e/SalaryData.txt [following]\n--2020-07-27 03:39:04--  https://gist.githubusercontent.com/solarillion/4d13184683407dfb0b36c7130fce1567/raw/329a94a79de4ba49e916c632a625e1d754506d3e/SalaryData.txt\nResolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.192.133, 151.101.0.133, 151.101.64.133, ...\nConnecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.192.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 320 [text/plain]\nSaving to: 'ml_salarydata'\n\n     0K                                                       100%  391K=0.001s\n\n2020-07-27 03:39:05 (391 KB/s) - 'ml_salarydata' saved [320/320]\n\n"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "! wget https://sf-mlbasics.firebaseio.com/CinemaData.json\n",
    "json_file=open('CinemaData.json','r')\n",
    "json_data=json_file.read()\n",
    "data=json.loads(json_data)\n",
    "df=pd.DataFrame(data)\n",
    "df.to_csv('Data\\CinemaData.csv')\n",
    "print(df)\n",
    "\n",
    "os.chdir(\"Data\")\n",
    "! wget http://rebrand.ly/ml_salarydata\n",
    "salary_dict=dict()\n",
    "\n",
    "with open('ml_salarydata','r') as f:\n",
    "    data=f.read()\n",
    "sal_list=data.splitlines()\n",
    "line1=sal_list[0].split(' ')\n",
    "salary_dict[line1[0]]=[]\n",
    "salary_dict[line1[1]]=[]\n",
    "for i in range(1,len(sal_list)):\n",
    "    line_splt=sal_list[i].split(' ')\n",
    "    salary_dict[line1[0]].append(line_splt[0])\n",
    "    salary_dict[line1[1]].append(line_splt[1])\n",
    "df=pd.DataFrame(salary_dict)\n",
    "print(df)\n",
    "df.to_csv('SalaryData.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Dataset Handling\n",
    "* You can find the Reviews Data in a RAR file in the 'Data' directory. Extract this dataset and use it for this module.\n",
    "\n",
    "* The dataset contains positive and negative movie reviews. The files 'Positive_Reviews.txt' and 'Negative_Reviews.txt' contain names of files having positive and negative reviews respectively. Create two directories ‘pos’ and ‘neg’, and segregate the reviews accordingly into the two directories.\n",
    "\n",
    "* Load ‘cv000_29590.csv’ and report the number of words present in the first column.\n",
    "\n",
    "* Find the number of unique words in the first column. For this task, ignore punctuations, that is, punctuations are not considered as a word or a part of it.\n",
    "\n",
    "* Lookups: OS module, String functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "26\ntotal number of words:  226\ntotal number of unique words 165\n"
    }
   ],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\Abi\\\\Desktop\\\\MLBasics\\\\Data\\\\Assignment_1_a\")\n",
    "os.mkdir(\"pos\")\n",
    "os.mkdir(\"neg\")\n",
    "full_list=os.listdir(\"Reviews\")\n",
    "source='C:\\\\Users\\\\Abi\\\\Desktop\\\\MLBasics\\\\Data\\\\Assignment_1_a\\\\Reviews\\\\'\n",
    "destination1='C:\\\\Users\\\\Abi\\\\Desktop\\\\MLBasics\\\\Data\\\\Assignment_1_a\\\\pos'\n",
    "destination2='C:\\\\Users\\\\Abi\\\\Desktop\\\\MLBasics\\\\Data\\\\Assignment_1_a\\\\neg'\n",
    "\n",
    "with open('Positive_Reviews.txt') as f:\n",
    "    data=f.read()\n",
    "temp=''\n",
    "for i in range(len(data)):\n",
    "    if(data[i]!='[' and data[i]!=']' and data[i]!='\\'' and data[i]!=','):\n",
    "        temp=temp+data[i]\n",
    "        if(data[i+1]=='\\''):\n",
    "            if(temp in full_list ):\n",
    "                shutil.copy((source+temp),destination1)\n",
    "            temp=''\n",
    "\n",
    "\n",
    "with open('Negative_Reviews.txt') as f:\n",
    "    data=f.read()\n",
    "temp=''\n",
    "for i in range(len(data)):\n",
    "    if(data[i]!='[' and data[i]!=']' and data[i]!='\\'' and data[i]!=','):\n",
    "        temp=temp+data[i]\n",
    "        if(data[i+1]=='\\''):\n",
    "            if(temp in full_list ):\n",
    "                shutil.copy((source+temp),destination2)\n",
    "            temp=''   \n",
    "\n",
    "delimiter = \"\\n\"\n",
    "with open(\"C:\\\\Users\\\\Abi\\\\Desktop\\\\MLBasics\\\\Data\\\\Assignment_1_a\\\\pos\\\\cv000_29590.txt\", \"r\") as paragraphs_file:\n",
    "    all_content = paragraphs_file.read() #reading all the content in one step\n",
    "    #using the string methods we split it\n",
    "    paragraphs = all_content.split(delimiter) \n",
    "\n",
    "print(len(paragraphs))\n",
    "df=pd.DataFrame(paragraphs,columns=['zxy'])\n",
    "df\n",
    "\n",
    "count=dict()\n",
    "for i in range(df.shape[0]):\n",
    "    row=df['zxy'][i].split(',')[0]\n",
    "    r=row.split()\n",
    "    for _ in r:\n",
    "        if(_ in count and _.isalpha()):\n",
    "            count[_]+=1\n",
    "        elif(_ not in count and _.isalpha()):\n",
    "            count[_]=1\n",
    "    \n",
    "count\n",
    "print(\"total number of words: \",sum(count.values()))\n",
    "print(\"total number of unique words\",len(count.keys()))       \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}